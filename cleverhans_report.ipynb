{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import timm\n",
    "import torchvision as tvision\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "from urllib.request import urlopen\n",
    "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
    "\n",
    "from cleverhans.torch.attacks.projected_gradient_descent import projected_gradient_descent\n",
    "from cleverhans.torch.attacks.carlini_wagner_l2 import carlini_wagner_l2\n",
    "\n",
    "class DoubleModelWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model.to(dtype=torch.double).cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.double)\n",
    "        outputs = self.model(x)\n",
    "        logits = outputs.logits.to(dtype=torch.double)\n",
    "        return logits\n",
    "    \n",
    "class DoubleModelTimmWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model.to(dtype=torch.double)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.double)\n",
    "        outputs = self.model(x)\n",
    "        return outputs.to(dtype=torch.double)\n",
    "\n",
    "\n",
    "# Setting up models\n",
    "\n",
    "mobile_model = timm.create_model('tf_mobilenetv3_large_minimal_100.in1k', pretrained=True)\n",
    "mobile_model = mobile_model.cuda().eval()\n",
    "mobile_model = DoubleModelTimmWrapper(mobile_model)\n",
    "\n",
    "mobile_data_config = timm.data.resolve_model_data_config(mobile_model)\n",
    "mobile_transforms = timm.data.create_transform(**mobile_data_config, is_training=False)\n",
    "\n",
    "vgg16_model = timm.create_model('vgg16.tv_in1k', pretrained=True)\n",
    "vgg16_model = vgg16_model.cuda().eval()\n",
    "vgg16_model = DoubleModelTimmWrapper(vgg16_model)\n",
    "\n",
    "vgg16_data_config = timm.data.resolve_model_data_config(vgg16_model)\n",
    "vgg16_transforms = timm.data.create_transform(**vgg16_data_config, is_training=False)\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "hf_resnet = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "resnet_model = DoubleModelWrapper(hf_resnet)\n",
    "\n",
    "\n",
    "# Downloading labels for ImageNet1k\n",
    "url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
    "imagenet_labels = requests.get(url).json()\n",
    "\n",
    "# prepare image\n",
    "# image = Image.open(urlopen(\"https://transforms.stlzoo.org/production/animals/red-kangaroo-02-01.jpg?w=1200&h=1200&auto=compress%2Cformat&fit=crop&dm=1654795233&s=5f137aa9a410a7ea3386c6972265111d\"))\n",
    "\n",
    "image_transforms = tvision.transforms.Compose([\n",
    "    tvision.transforms.Resize((224, 224)),\n",
    "    tvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# image = image_transforms(image).unsqueeze(0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clever_with_pgd(image_url: str, model: torch.nn.Module, target_id: int = 123):\n",
    "    image = Image.open(urlopen(image_url))\n",
    "\n",
    "    input_img = image_transforms(image).unsqueeze(0)\n",
    "\n",
    "    arr = np.zeros(1)\n",
    "    arr[0] = imagenet_labels[target_id]\n",
    "    target_tensor = torch.from_numpy(arr).to(dtype=torch.long).cuda()\n",
    "\n",
    "    adv_img = projected_gradient_descent(model, input_img, norm=np.inf, eps=0.3, eps_iter=0.1, nb_iter=40, targeted=True, y=target_tensor)\n",
    "\n",
    "    return adv_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clever_with_cw2(image_url: str, model: torch.nn.Module, target_id: int = 123):\n",
    "    image = Image.open(urlopen(image_url))\n",
    "\n",
    "    input_img = image_transforms(image).unsqueeze(0)\n",
    "\n",
    "    arr = np.zeros(1)\n",
    "    arr[0] = imagenet_labels[target_id]\n",
    "    target_tensor = torch.from_numpy(arr).to(dtype=torch.long).cuda()\n",
    "\n",
    "    adv_img = carlini_wagner_l2(model, input_img, n_classes=len(imagenet_labels), targeted=True, y=target_tensor, lr=0.1, max_iterations=10, binary_search_steps=10)\n",
    "\n",
    "    return adv_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    'CarliniWagnerL2': clever_with_cw2,\n",
    "    'PGD': clever_with_pgd,\n",
    "}\n",
    "\n",
    "image_url = 'https://as2.ftcdn.net/v2/jpg/03/05/26/83/1000_F_305268343_5Xi5esuvd6mIOqFC0QXZdCcqIWNQ6HR2.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_methods(methods: dict, image_url: str, model, num_of_iters: int = 5):\n",
    "    \"\"\"\n",
    "    Benchmark a set of adversarial attack methods.\n",
    "\n",
    "    Args:\n",
    "        methods (dict): Dictionary of attack methods {method_name: function}.\n",
    "        image_url (str): URL of the input image.\n",
    "        model: Pretrained model to attack.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Benchmarking results as a tidy table.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for method_name, method in methods.items():\n",
    "        times = []\n",
    "        probabilities_before = []\n",
    "        probabilities_after = []\n",
    "        label_before = []\n",
    "        label_after = []\n",
    "        # successes = []\n",
    "\n",
    "        print(f\"Benchmarking {method_name}...\")\n",
    "\n",
    "        for _ in range(num_of_iters):  # Run each method x times\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Run the adversarial method\n",
    "            raw_adversarial = method(image_url, model)\n",
    "            \n",
    "            img = Image.open(urlopen(image_url))\n",
    "            input_tensor = image_transforms(img).unsqueeze(0).cuda()\n",
    "            \n",
    "            \n",
    "            # Measure time\n",
    "            elapsed_time = time.time() - start_time\n",
    "            times.append(elapsed_time)\n",
    "            \n",
    "            # Collect probabilities\n",
    "            with torch.no_grad():\n",
    "                # For the original input\n",
    "                logits_before = model(input_tensor)\n",
    "                probabilities_before_run = torch.nn.functional.softmax(logits_before, dim=1)\n",
    "                probabilities_before.append(torch.max(probabilities_before_run).cpu().detach().numpy())\n",
    "                label_before.append(int(torch.argmax(logits_before).cpu().detach().numpy()))\n",
    "                \n",
    "                \n",
    "\n",
    "                # For the adversarial input\n",
    "                logits_after = model(raw_adversarial)\n",
    "                probabilities_after_run = torch.nn.functional.softmax(logits_after, dim=1)\n",
    "                probabilities_after.append(torch.max(probabilities_after_run).cpu().detach().numpy())\n",
    "                label_after.append(int(torch.argmax(logits_after).cpu().detach().numpy()))\n",
    "                \n",
    "            \n",
    "            # Track success\n",
    "            # successes.append(success)\n",
    "        \n",
    "        # Store results for this method\n",
    "        results.append({\n",
    "            \"Method\": method_name,\n",
    "            \"Avg Time (s)\": np.mean(times),\n",
    "            \"Avg Prob Before\": np.mean(probabilities_before),\n",
    "            \"Avg Prob After\": np.mean(probabilities_after),\n",
    "            \"Predicted Label Before\": label_before,\n",
    "            \"Predicted Label After\": label_after,\n",
    "            # \"Success Rate\": np.mean(successes),\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame for a tidy table\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(benchmark_methods(methods, image_url, mobile_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(benchmark_methods(methods, image_url, resnet_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(benchmark_methods(methods, image_url, vgg16_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
