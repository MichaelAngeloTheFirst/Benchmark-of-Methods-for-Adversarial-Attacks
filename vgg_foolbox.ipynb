{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michaelangelo/Benchmark-of-Methods-for-Adversarial-Attacks/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import foolbox as fb\n",
    "import timm\n",
    "from PIL import Image\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import numpy as np\n",
    "import torchvision as tivision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = timm.create_model('vgg16.tv_in1k', pretrained=True)\n",
    "vgg_model = vgg_model.cuda().eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO LABELS PROVIDED! \n",
    "However in docs we can see than this model was trained on ImageNet1k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
    "imagenet_labels = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_for_image(image_url: str, model_name: str = 'vgg16.tv_in1k'):\n",
    "    model = timm.create_model(model_name, pretrained=True)\n",
    "    model.eval()\n",
    "    \n",
    "    img = Image.open(urlopen(image_url))\n",
    "\n",
    "    image_transforms = tivision.transforms.Compose([\n",
    "        tivision.transforms.Resize((224,224)),\n",
    "        tivision.transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "    data_config = timm.data.resolve_model_data_config(model)\n",
    "    \n",
    "    transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "    input_tensor = image_transforms(img).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)\n",
    "    \n",
    "    probabilities = torch.nn.functional.softmax(logits[0], dim=0)\n",
    "    \n",
    "    url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
    "    imagenet_labels = requests.get(url).json()\n",
    "    \n",
    "    assert len(imagenet_labels) == logits.shape[1], \"Mismatch between labels and logits\"\n",
    "    \n",
    "    predicted_index = torch.argmax(probabilities).item()\n",
    "    predicted_label = imagenet_labels[predicted_index]\n",
    "    \n",
    "    return predicted_label, probabilities[predicted_index].item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: great egret with confidence: 18.57%\n",
      "Predicted Label: ostrich with confidence: 42.62%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img_list = [\n",
    "    'https://as2.ftcdn.net/v2/jpg/03/05/26/83/1000_F_305268343_5Xi5esuvd6mIOqFC0QXZdCcqIWNQ6HR2.jpg',\n",
    "    'https://as2.ftcdn.net/v2/jpg/02/41/23/39/1000_F_241233928_3UtxKpchsTSbR4iJG9j8xSRYh3I8MyzG.jpg'\n",
    "]\n",
    "\n",
    "for image_url in img_list:\n",
    "    label, confidence = get_label_for_image(image_url)\n",
    "    print(f\"Predicted Label: {label} with confidence: {confidence * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fool_model_with_pgd(image_url: str, model):\n",
    "    \n",
    "    # Foolbox model wrapper\n",
    "    fmodel = fb.PyTorchModel(\n",
    "        model, \n",
    "        bounds=(0, 1), \n",
    "    )\n",
    "\n",
    "    image_transforms = tivision.transforms.Compose([\n",
    "        tivision.transforms.Resize((224,224)),\n",
    "        tivision.transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    img = Image.open(urlopen(image_url))\n",
    "    img_tensor = image_transforms(img).unsqueeze(0).cuda()\n",
    "\n",
    "\n",
    "    np_arr = np.zeros(1)\n",
    "    np_arr[0] = 123\n",
    "\n",
    "    label = torch.from_numpy(np_arr).to(dtype=torch.long).cuda()\n",
    "    criterion= fb.criteria.TargetedMisclassification(label)\n",
    "\n",
    "    attack = fb.attacks.LinfPGD()\n",
    "    raw_adversarial, _, success = attack(fmodel, img_tensor, criterion=criterion, epsilons=0.1)\n",
    "    \n",
    "    adversarial_label = torch.argmax(fmodel(raw_adversarial)).item()\n",
    "    \n",
    "    return raw_adversarial, success, label, adversarial_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_adversarial,  success, label, adversarial_label = fool_model_with_pgd(    'https://as2.ftcdn.net/v2/jpg/03/05/26/83/1000_F_305268343_5Xi5esuvd6mIOqFC0QXZdCcqIWNQ6HR2.jpg', vgg_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spiny lobster\n"
     ]
    }
   ],
   "source": [
    "print(imagenet_labels[adversarial_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSMA NOT PRESENT IN FOOLBOX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARLINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fool_model_with_cwl2(image_url: str, model):\n",
    " \n",
    "    \n",
    "    # Foolbox model wrapper\n",
    "    fmodel = fb.PyTorchModel(\n",
    "        model, \n",
    "        bounds=(0, 1), \n",
    "    )\n",
    "\n",
    "    image_transforms = tivision.transforms.Compose([\n",
    "        tivision.transforms.Resize((224,224)),\n",
    "        tivision.transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    img = Image.open(urlopen(image_url))\n",
    "    img_tensor = image_transforms(img).unsqueeze(0).cuda()\n",
    "\n",
    "\n",
    "    np_arr = np.zeros(1)\n",
    "    np_arr[0] = 123\n",
    "\n",
    "    label = torch.from_numpy(np_arr).to(dtype=torch.long).cuda()\n",
    "    criterion= fb.criteria.TargetedMisclassification(label)\n",
    "\n",
    "    attack = fb.attacks.L2CarliniWagnerAttack(binary_search_steps=10,steps = 100, stepsize=0.1, confidence=0.0)\n",
    "    raw_adversarial, _, success = attack(fmodel, img_tensor, criterion=criterion, epsilons=0.1)\n",
    "    \n",
    "    adversarial_label = torch.argmax(fmodel(raw_adversarial)).item()\n",
    "    \n",
    "    return raw_adversarial, success, label, adversarial_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_adversarial,  success, label, adversarial_label = fool_model_with_cwl2(    'https://as2.ftcdn.net/v2/jpg/03/05/26/83/1000_F_305268343_5Xi5esuvd6mIOqFC0QXZdCcqIWNQ6HR2.jpg', vgg_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spiny lobster\n"
     ]
    }
   ],
   "source": [
    "print(imagenet_labels[adversarial_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "print(adversarial_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOOLBOX L2DEEPFOOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fool_model_with_deepfool(image_url: str,model, label=9):\n",
    "    \n",
    "    # Foolbox model wrapper\n",
    "    fmodel = fb.PyTorchModel(\n",
    "        model, \n",
    "        bounds=(0, 1), \n",
    "    )\n",
    "\n",
    "    image_transforms = tivision.transforms.Compose([\n",
    "        tivision.transforms.Resize((224,224)),\n",
    "        tivision.transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    img = Image.open(urlopen(image_url))\n",
    "    img_tensor = image_transforms(img).unsqueeze(0).cuda()\n",
    "\n",
    "\n",
    "    np_arr = np.zeros(1)\n",
    "    np_arr[0] = label\n",
    "    \n",
    "    labels = torch.from_numpy(np_arr).to(dtype=torch.long).cuda()\n",
    "    criterion= fb.criteria.Misclassification(labels=labels)\n",
    "\n",
    "    attack = fb.attacks.L2DeepFoolAttack(steps=100, candidates=10, overshoot=0.000001, )\n",
    "    raw_adversarial, _, success = attack(fmodel, img_tensor, criterion=criterion, epsilons=0.1)\n",
    "    \n",
    "    # Check the new adversarial label\n",
    "    adversarial_label = torch.argmax(fmodel(raw_adversarial)).item()\n",
    "    \n",
    "    return raw_adversarial,  success, label, adversarial_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_adversarial, success, label, adversarial_label = fool_model_with_deepfool('https://transforms.stlzoo.org/production/animals/red-kangaroo-02-01.jpg?w=1200&h=1200&auto=compress%2Cformat&fit=crop&dm=1654795233&s=5f137aa9a410a7ea3386c6972265111d',vgg_model ,imagenet_labels.index('dingo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hare\n"
     ]
    }
   ],
   "source": [
    "print(imagenet_labels[adversarial_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EADEN ATTACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fool_model_with_eaden(image_url: str,model ,label=9):\n",
    "\n",
    "    # Foolbox model wrapper\n",
    "    fmodel = fb.PyTorchModel(\n",
    "        model, \n",
    "        bounds=(0, 1), \n",
    "    )\n",
    "\n",
    "    image_transforms = tivision.transforms.Compose([\n",
    "        tivision.transforms.Resize((224,224)),\n",
    "        tivision.transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    img = Image.open(urlopen(image_url))\n",
    "    img_tensor = image_transforms(img).unsqueeze(0).cuda()\n",
    "\n",
    "\n",
    "    np_arr = np.zeros(1)\n",
    "    np_arr[0] = label\n",
    "    \n",
    "    labels = torch.from_numpy(np_arr).to(dtype=torch.long).cuda()\n",
    "    criterion= fb.criteria.Misclassification(labels=labels)\n",
    "\n",
    "    attack = fb.attacks.EADAttack(binary_search_steps=10, steps=10,decision_rule='EN', )\n",
    "    raw_adversarial, _, success = attack(fmodel, img_tensor, criterion=criterion, epsilons=0.1)\n",
    "    \n",
    "    # Check the new adversarial label\n",
    "    adversarial_label = torch.argmax(fmodel(raw_adversarial)).item()\n",
    "    \n",
    "    return raw_adversarial, success, label, adversarial_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_adversarial, success, label, adversarial_label = fool_model_with_eaden('https://transforms.stlzoo.org/production/animals/red-kangaroo-02-01.jpg?w=1200&h=1200&auto=compress%2Cformat&fit=crop&dm=1654795233&s=5f137aa9a410a7ea3386c6972265111d',vgg_model ,imagenet_labels.index('dingo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hare\n"
     ]
    }
   ],
   "source": [
    "print(imagenet_labels[adversarial_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOPSKIPJUMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fool_model_with_hopskipjump(image_url: str, model ,label=9):\n",
    "    \n",
    "    # Foolbox model wrapper\n",
    "    fmodel = fb.PyTorchModel(\n",
    "        model, \n",
    "        bounds=(0, 1), \n",
    "    )\n",
    "\n",
    "    image_transforms = tivision.transforms.Compose([\n",
    "        tivision.transforms.Resize((224,224)),\n",
    "        tivision.transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    img = Image.open(urlopen(image_url))\n",
    "    img_tensor = image_transforms(img).unsqueeze(0).cuda()\n",
    "\n",
    "\n",
    "    np_arr = np.zeros(1)\n",
    "    np_arr[0] = label\n",
    "    \n",
    "    labels = torch.from_numpy(np_arr).to(dtype=torch.long).cuda()\n",
    "    criterion= fb.criteria.Misclassification(labels=labels)\n",
    "\n",
    "    attack = fb.attacks.HopSkipJumpAttack(steps=10,)\n",
    "    raw_adversarial, _, success = attack(fmodel, img_tensor, criterion=criterion, epsilons=0.1)\n",
    "    \n",
    "    # Check the new adversarial label\n",
    "    adversarial_label = torch.argmax(fmodel(raw_adversarial)).item()\n",
    "    \n",
    "    return raw_adversarial, success, label, adversarial_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_adversarial, success, label, adversarial_label = fool_model_with_hopskipjump('https://transforms.stlzoo.org/production/animals/red-kangaroo-02-01.jpg?w=1200&h=1200&auto=compress%2Cformat&fit=crop&dm=1654795233&s=5f137aa9a410a7ea3386c6972265111d',vgg_model ,imagenet_labels.index('dingo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coyote\n"
     ]
    }
   ],
   "source": [
    "print(imagenet_labels[adversarial_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_methods(methods: dict, image_url: str, model, num_of_iters=7):\n",
    "    \"\"\"\n",
    "    Benchmark a set of adversarial attack methods.\n",
    "\n",
    "    Args:\n",
    "        methods (dict): Dictionary of attack methods {method_name: function}.\n",
    "        image_url (str): URL of the input image.\n",
    "        model: Pretrained model to attack.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Benchmarking results as a tidy table.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    data_config = timm.data.resolve_model_data_config(model)\n",
    "    image_transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "\n",
    "    for method_name, method in methods.items():\n",
    "        times = []\n",
    "        probabilities_before = []\n",
    "        probabilities_after = []\n",
    "        label_before = []\n",
    "        label_after = []\n",
    "        # successes = []\n",
    "\n",
    "        print(f\"Benchmarking {method_name}...\")\n",
    "\n",
    "        for _ in range(num_of_iters):  # Run each method 3 times\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Run the adversarial method\n",
    "            outputs = method(image_url, model)\n",
    "            raw_adversarial, _, _, _ = outputs\n",
    "            \n",
    "            img = Image.open(urlopen(image_url))\n",
    "            input_tensor = image_transforms(img).unsqueeze(0).cuda()\n",
    "            \n",
    "            \n",
    "            # Measure time\n",
    "            elapsed_time = time.time() - start_time\n",
    "            times.append(elapsed_time)\n",
    "            \n",
    "            # Collect probabilities\n",
    "            with torch.no_grad():\n",
    "                # For the original input\n",
    "                logits_before = model(input_tensor)\n",
    "                probabilities_before_run = torch.nn.functional.softmax(logits_before[0], dim=0)\n",
    "                probabilities_before.append(torch.max(probabilities_before_run).cpu().detach().numpy())\n",
    "                label_before.append(int(torch.argmax(logits_before).cpu().detach().numpy()))\n",
    "                \n",
    "                \n",
    "\n",
    "                # For the adversarial input\n",
    "                logits_after = model(raw_adversarial)\n",
    "                probabilities_after_run = torch.nn.functional.softmax(logits_after, dim=1)\n",
    "                probabilities_after.append(torch.max(probabilities_after_run).cpu().detach().numpy())\n",
    "                label_after.append(int(torch.argmax(logits_after).cpu().detach().numpy()))\n",
    "                \n",
    "            \n",
    "            # Track success\n",
    "            # successes.append(success)\n",
    "        \n",
    "        # Store results for this method\n",
    "        results.append({\n",
    "            \"Method\": method_name,\n",
    "            \"Avg Time (s)\": np.mean(times),\n",
    "            \"Avg Prob Before\": np.mean(probabilities_before),\n",
    "            \"Avg Prob After\": np.mean(probabilities_after),\n",
    "            \"Predicted Label Before\": label_before,\n",
    "            \"Predicted Label After\": label_after,\n",
    "            # \"Success Rate\": np.mean(successes),\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame for a tidy table\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking CW_L2...\n",
      "Benchmarking PGD...\n",
      "Benchmarking HopSkipJump...\n",
      "Benchmarking DeepFool...\n",
      "Benchmarking EAD_EN...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Avg Time (s)</th>\n",
       "      <th>Avg Prob Before</th>\n",
       "      <th>Avg Prob After</th>\n",
       "      <th>Predicted Label Before</th>\n",
       "      <th>Predicted Label After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CW_L2</td>\n",
       "      <td>34.526212</td>\n",
       "      <td>0.998978</td>\n",
       "      <td>0.222788</td>\n",
       "      <td>[9, 9, 9, 9, 9]</td>\n",
       "      <td>[123, 123, 123, 123, 123]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PGD</td>\n",
       "      <td>5.903388</td>\n",
       "      <td>0.998978</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>[9, 9, 9, 9, 9]</td>\n",
       "      <td>[123, 123, 123, 123, 123]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HopSkipJump</td>\n",
       "      <td>127.597958</td>\n",
       "      <td>0.998978</td>\n",
       "      <td>0.185621</td>\n",
       "      <td>[9, 9, 9, 9, 9]</td>\n",
       "      <td>[132, 132, 132, 132, 132]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeepFool</td>\n",
       "      <td>0.827010</td>\n",
       "      <td>0.998978</td>\n",
       "      <td>0.185621</td>\n",
       "      <td>[9, 9, 9, 9, 9]</td>\n",
       "      <td>[132, 132, 132, 132, 132]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EAD_EN</td>\n",
       "      <td>19.370939</td>\n",
       "      <td>0.998978</td>\n",
       "      <td>0.185621</td>\n",
       "      <td>[9, 9, 9, 9, 9]</td>\n",
       "      <td>[132, 132, 132, 132, 132]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Method  Avg Time (s)  Avg Prob Before  Avg Prob After  \\\n",
       "0        CW_L2     34.526212         0.998978        0.222788   \n",
       "1          PGD      5.903388         0.998978        0.999999   \n",
       "2  HopSkipJump    127.597958         0.998978        0.185621   \n",
       "3     DeepFool      0.827010         0.998978        0.185621   \n",
       "4       EAD_EN     19.370939         0.998978        0.185621   \n",
       "\n",
       "  Predicted Label Before      Predicted Label After  \n",
       "0        [9, 9, 9, 9, 9]  [123, 123, 123, 123, 123]  \n",
       "1        [9, 9, 9, 9, 9]  [123, 123, 123, 123, 123]  \n",
       "2        [9, 9, 9, 9, 9]  [132, 132, 132, 132, 132]  \n",
       "3        [9, 9, 9, 9, 9]  [132, 132, 132, 132, 132]  \n",
       "4        [9, 9, 9, 9, 9]  [132, 132, 132, 132, 132]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "methods = {\n",
    "    \"CW_L2\": fool_model_with_cwl2,\n",
    "    \"PGD\": fool_model_with_pgd,\n",
    "    \"HopSkipJump\": fool_model_with_hopskipjump,\n",
    "    \"DeepFool\": fool_model_with_deepfool,\n",
    "    \"EAD_EN\": fool_model_with_eaden,\n",
    "}\n",
    "\n",
    "\n",
    "image_url ='https://as2.ftcdn.net/v2/jpg/03/05/26/83/1000_F_305268343_5Xi5esuvd6mIOqFC0QXZdCcqIWNQ6HR2.jpg'  \n",
    "\n",
    "\n",
    "benchmark_results = benchmark_methods(methods, image_url, vgg_model, num_of_iters=5)\n",
    "\n",
    "display(benchmark_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
